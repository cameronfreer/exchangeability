/-
Copyright (c) 2025 Cameron Freer. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: Cameron Freer
-/
import Mathlib.Probability.ConditionalExpectation
import Mathlib.MeasureTheory.Function.ConditionalExpectation.Basic
import Mathlib.MeasureTheory.Measure.Typeclasses.Probability
import Exchangeability.Probability.CondExpHelpers

/-!
# Conditional Independence

This file defines conditional independence for random variables and establishes
basic properties. The definition uses indicator functions on measurable rectangles,
which can then be extended to bounded measurable functions via monotone class arguments.

## Main definitions

* `CondIndep Y Z W Î¼`: Y and Z are conditionally independent given W under measure Î¼,
  denoted Y âŠ¥âŠ¥_W Z, defined via indicator test functions on Borel sets.

## Main results

* `condIndep_symm`: Conditional independence is symmetric (Y âŠ¥âŠ¥_W Z â†” Z âŠ¥âŠ¥_W Y)
* `condIndep_of_indep`: Unconditional independence implies conditional independence

## Implementation notes

We use an indicator-based characterization rather than Ïƒ-algebra formalism to avoid
requiring a full conditional distribution API. The definition states that for all
Borel sets A, B:

  E[1_A(Y) Â· 1_B(Z) | Ïƒ(W)] = E[1_A(Y) | Ïƒ(W)] Â· E[1_B(Z) | Ïƒ(W)]  a.e.

This is equivalent to the standard Ïƒ-algebra definition but more elementary to work with.

## References

* Kallenberg (2005), *Probabilistic Symmetries and Invariance Principles*, Section 6.1
* Kallenberg (2002), *Foundations of Modern Probability*, Chapter 6

## TODO

* Extend from indicators to bounded measurable functions (monotone class argument)
* Prove conditional independence from distributional equality (Kallenberg Lemma 1.3)
* Prove projection property: If Y âŠ¥âŠ¥_W Z, then E[f(Y)|Ïƒ(Z,W)] = E[f(Y)|Ïƒ(W)]

-/

noncomputable section
open scoped MeasureTheory ENNReal
open MeasureTheory ProbabilityTheory Set

variable {Î© Î± Î² Î³ : Type*}
variable [MeasurableSpace Î©] [MeasurableSpace Î±] [MeasurableSpace Î²] [MeasurableSpace Î³]

/-!
## Definition of conditional independence
-/

/-- **Conditional independence via indicator test functions.**

Random variables Y and Z are **conditionally independent given W** under measure Î¼,
denoted Y âŠ¥âŠ¥_W Z, if for all Borel sets A and B:

  E[1_A(Y) Â· 1_B(Z) | Ïƒ(W)] = E[1_A(Y) | Ïƒ(W)] Â· E[1_B(Z) | Ïƒ(W)]  a.e.

**Mathematical content:** This says that knowing W, the events {Y âˆˆ A} and {Z âˆˆ B}
are independent: P(Y âˆˆ A, Z âˆˆ B | W) = P(Y âˆˆ A | W) Â· P(Z âˆˆ B | W).

**Why indicators suffice:** By linearity and approximation, this extends to all bounded
measurable functions. The key is that indicators generate the bounded measurable functions
via monotone class arguments.

**Relation to Ïƒ-algebra definition:** This is equivalent to Ïƒ(Y) âŠ¥âŠ¥_Ïƒ(W) Ïƒ(Z), but
stated more elementarily without requiring full conditional probability machinery.

**Implementation:** We use `Set.indicator` for the characteristic function 1_A.
-/
def CondIndep {Î© Î± Î² Î³ : Type*}
    [MeasurableSpace Î©] [MeasurableSpace Î±] [MeasurableSpace Î²] [MeasurableSpace Î³]
    (Î¼ : Measure Î©) (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³) : Prop :=
  âˆ€ (A : Set Î±) (B : Set Î²), MeasurableSet A â†’ MeasurableSet B â†’
    Î¼[ (Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))) *
       (Set.indicator (Z â»Â¹' B) (fun _ => (1 : â„)))
       | MeasurableSpace.comap W inferInstance ]
      =áµ[Î¼]
    Î¼[ Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
       | MeasurableSpace.comap W inferInstance ]
    *
    Î¼[ Set.indicator (Z â»Â¹' B) (fun _ => (1 : â„))
       | MeasurableSpace.comap W inferInstance ]

/-!
## Basic properties
-/

/-- **Symmetry of conditional independence.**

If Y âŠ¥âŠ¥_W Z, then Z âŠ¥âŠ¥_W Y. This follows immediately from commutativity of multiplication.
-/
theorem condIndep_symm (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³) :
    CondIndep Î¼ Y Z W â†” CondIndep Î¼ Z Y W := by
  constructor <;> intro h A B hA hB
  Â· -- Y âŠ¥âŠ¥_W Z implies Z âŠ¥âŠ¥_W Y
    have := h B A hB hA
    -- Swap multiplication order
    simp only [mul_comm] at this âŠ¢
    exact this
  Â· -- Z âŠ¥âŠ¥_W Y implies Y âŠ¥âŠ¥_W Z (same proof by symmetry)
    have := h B A hB hA
    simp only [mul_comm] at this âŠ¢
    exact this

/-!
## Helper lemmas for independence and conditional expectation
-/

/-- **Conditional expectation against an independent Ïƒ-algebra is constant.**

If X is integrable and measurable with respect to a Ïƒ-algebra independent of Ïƒ(W),
then E[X | Ïƒ(W)] = E[X] almost everywhere.

This is the key property that makes independence "pass through" conditioning:
knowing W provides no information about X when X âŠ¥ W.
-/
lemma condExp_const_of_indepFun (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    {X : Î© â†’ â„} {W : Î© â†’ Î³}
    (hX : Measurable X) (hW : Measurable W)
    (h_indep : IndepFun X W Î¼)
    (hX_int : Integrable X Î¼) :
    Î¼[X | MeasurableSpace.comap W inferInstance] =áµ[Î¼] (fun _ => Î¼[X]) := by
  -- Convert IndepFun to Indep of Ïƒ-algebras
  rw [IndepFun_iff_Indep] at h_indep
  -- Apply condExp_indep_eq: E[X|Ïƒ(W)] = E[X] when Ïƒ(X) âŠ¥ Ïƒ(W)
  refine condExp_indep_eq hX.comap_le hW.comap_le ?_ h_indep
  -- X is Ïƒ(X)-strongly measurable (X is measurable from (Î©, Ïƒ(X)) to â„ by definition of comap)
  have : @Measurable Î© â„ (MeasurableSpace.comap X inferInstance) inferInstance X :=
    Measurable.of_comap_le le_rfl
  exact this.stronglyMeasurable

/-- Extract independence of first component from pair independence. -/
lemma IndepFun.of_comp_left_fst {Y : Î© â†’ Î±} {Z : Î© â†’ Î²} {W : Î© â†’ Î³}
    (h : IndepFun (fun Ï‰ => (Y Ï‰, Z Ï‰)) W Î¼) :
    IndepFun Y W Î¼ := by
  -- Y = Prod.fst âˆ˜ (fun Ï‰ => (Y Ï‰, Z Ï‰))
  -- So Y âŠ¥ W follows from (Y,Z) âŠ¥ W by composition
  have : Y = Prod.fst âˆ˜ (fun Ï‰ => (Y Ï‰, Z Ï‰)) := by rfl
  rw [this]
  exact h.comp measurable_fst measurable_id

/-- Extract independence of second component from pair independence. -/
lemma IndepFun.of_comp_left_snd {Y : Î© â†’ Î±} {Z : Î© â†’ Î²} {W : Î© â†’ Î³}
    (h : IndepFun (fun Ï‰ => (Y Ï‰, Z Ï‰)) W Î¼) :
    IndepFun Z W Î¼ := by
  -- Z = Prod.snd âˆ˜ (fun Ï‰ => (Y Ï‰, Z Ï‰))
  -- So Z âŠ¥ W follows from (Y,Z) âŠ¥ W by composition
  have : Z = Prod.snd âˆ˜ (fun Ï‰ => (Y Ï‰, Z Ï‰)) := by rfl
  rw [this]
  exact h.comp measurable_snd measurable_id

/-!
## Conditional independence from unconditional independence
-/

/-- **Independence plus independence of pair from W implies conditional independence.**

If Y and Z are (unconditionally) independent, and the pair (Y,Z) is independent of W,
then Y âŠ¥âŠ¥_W Z.

**Key insight:** Independence of (Y,Z) from W means the conditional law of (Y,Z) given W
equals the unconditional law, so the factorization E[1_A(Y)Â·1_B(Z)] = E[1_A(Y)]Â·E[1_B(Z)]
survives conditioning on W.

**Counterexample showing Y âŠ¥ Z alone is NOT enough:**
- Y, Z: independent fair coin flips
- W := Y + Z
- Then Y âŠ¥ Z unconditionally, but P(Y=1|Z=1,W=1) = 1 â‰  1/2 = P(Y=1|W=1),
  so Y and Z are NOT conditionally independent given W.

**Proof strategy:**
1. Since (Y,Z) âŠ¥ W, conditional expectation of any function of (Y,Z) given Ïƒ(W)
   is the constant E[that function].
2. Apply to 1_A(Y), 1_B(Z), and their product.
3. The unconditional factorization E[1_A(Y)Â·1_B(Z)] = E[1_A(Y)]Â·E[1_B(Z)] (from Y âŠ¥ Z)
   transfers to the conditional expectations.
-/
theorem condIndep_of_indep_pair (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³)
    (hY : Measurable Y) (hZ : Measurable Z) (hW : Measurable W)
    (hYZ_indep : IndepFun Y Z Î¼)
    (hPairW_indep : IndepFun (fun Ï‰ => (Y Ï‰, Z Ï‰)) W Î¼) :
    CondIndep Î¼ Y Z W := by
  intro A B hA hB
  -- Define the indicator functions
  let f := Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
  let g := Set.indicator (Z â»Â¹' B) (fun _ => (1 : â„))

  -- f and g are measurable and integrable
  have hf_meas : Measurable f := measurable_const.indicator (hY hA)
  have hg_meas : Measurable g := measurable_const.indicator (hZ hB)
  have hf_int : Integrable f Î¼ := (integrable_const (1 : â„)).indicator (hY hA)
  have hg_int : Integrable g Î¼ := (integrable_const (1 : â„)).indicator (hZ hB)

  -- Y and Z are independent of W (from pair independence)
  have hY_W_indep : IndepFun Y W Î¼ := IndepFun.of_comp_left_fst hPairW_indep
  have hZ_W_indep : IndepFun Z W Î¼ := IndepFun.of_comp_left_snd hPairW_indep

  -- f and g are independent of W (since they are Ïƒ(Y)- and Ïƒ(Z)-measurable)
  have hf_W_indep : IndepFun f W Î¼ := by
    -- f is measurable with respect to Ïƒ(Y)
    have : f = (fun a => Set.indicator A (fun _ => (1 : â„)) a) âˆ˜ Y := by
      ext Ï‰
      simp only [f, Function.comp_apply, Set.indicator]
      split_ifs with h <;> simp [h]
    rw [this]
    exact hY_W_indep.comp (measurable_const.indicator hA) measurable_id
  have hg_W_indep : IndepFun g W Î¼ := by
    -- g is measurable with respect to Ïƒ(Z)
    have : g = (fun b => Set.indicator B (fun _ => (1 : â„)) b) âˆ˜ Z := by
      ext Ï‰
      simp only [g, Function.comp_apply, Set.indicator]
      split_ifs with h <;> simp [h]
    rw [this]
    exact hZ_W_indep.comp (measurable_const.indicator hB) measurable_id

  -- By independence from W, conditional expectations are constants
  have hf_const : Î¼[f | MeasurableSpace.comap W inferInstance] =áµ[Î¼] fun _ => Î¼[f] :=
    condExp_const_of_indepFun Î¼ hf_meas hW hf_W_indep hf_int
  have hg_const : Î¼[g | MeasurableSpace.comap W inferInstance] =áµ[Î¼] fun _ => Î¼[g] :=
    condExp_const_of_indepFun Î¼ hg_meas hW hg_W_indep hg_int

  -- Product is also independent of W (since (Y,Z) âŠ¥ W)
  have hfg_meas : Measurable (f * g) := hf_meas.mul hg_meas
  have hfg_int : Integrable (f * g) Î¼ := by
    refine âŸ¨hfg_meas.aestronglyMeasurable, ?_âŸ©
    simp only [hasFiniteIntegral_iff_norm]
    apply lt_of_le_of_lt
    Â· apply lintegral_mono
      intro Ï‰
      simp [f, g, Set.indicator]
      split_ifs <;> norm_num
    Â· simp
      exact measure_lt_top Î¼ Set.univ

  -- The product function is a function of (Y, Z), hence independent of W
  have h_pair_indep : IndepFun (f * g) W Î¼ := by
    -- f * g = Ï† âˆ˜ (Y, Z) where Ï†(a, b) = 1_A(a) * 1_B(b)
    have hfg_eq : f * g = (fun p : Î± Ã— Î² =>
        Set.indicator A (fun _ => (1 : â„)) (p.1) *
        Set.indicator B (fun _ => (1 : â„)) (p.2)) âˆ˜ (fun Ï‰ => (Y Ï‰, Z Ï‰)) := by
      ext Ï‰
      simp only [Pi.mul_apply, f, g, Function.comp_apply]
      rw [Set.indicator_comp_of_zero fun _ => (0 : â„),
          Set.indicator_comp_of_zero fun _ => (0 : â„)]
    rw [hfg_eq]
    conv_rhs => rw [â† Function.comp.left_id W]
    exact hPairW_indep.comp ((measurable_const.indicator hA).fst'.mul (measurable_const.indicator hB).snd') measurable_id

  have hfg_const : Î¼[f * g | MeasurableSpace.comap W inferInstance] =áµ[Î¼] fun _ => Î¼[f * g] :=
    condExp_const_of_indepFun Î¼ hfg_meas hW h_pair_indep hfg_int

  -- Unconditional factorization from Y âŠ¥ Z: f and g are independent
  have hfg_indep : IndepFun f g Î¼ := by
    -- f = Ï†â‚ âˆ˜ Y, g = Ï†â‚‚ âˆ˜ Z where Ï†â‚, Ï†â‚‚ are indicator functions
    have hf_eq : f = (fun a => Set.indicator A (fun _ => (1 : â„)) a) âˆ˜ Y := by
      ext Ï‰
      simp only [f, Function.comp_apply]
      rw [Set.indicator_comp_of_zero fun _ => (0 : â„)]
    have hg_eq : g = (fun b => Set.indicator B (fun _ => (1 : â„)) b) âˆ˜ Z := by
      ext Ï‰
      simp only [g, Function.comp_apply]
      rw [Set.indicator_comp_of_zero fun _ => (0 : â„)]
    rw [hf_eq, hg_eq]
    exact hYZ_indep.comp (measurable_const.indicator hA) (measurable_const.indicator hB)
  have hYZ_factor : Î¼[f * g] = Î¼[f] * Î¼[g] :=
    hfg_indep.integral_mul_of_integrable hf_int hg_int

  -- Combine everything
  calc Î¼[f * g | MeasurableSpace.comap W inferInstance]
      =áµ[Î¼] fun _ => Î¼[f * g] := hfg_const
    _ = fun _ => Î¼[f] * Î¼[g] := by rw [hYZ_factor]
    _ =áµ[Î¼] (fun _ => Î¼[f]) * (fun _ => Î¼[g]) := by rfl
    _ =áµ[Î¼] Î¼[f | MeasurableSpace.comap W inferInstance] *
             Î¼[g | MeasurableSpace.comap W inferInstance] := by
      filter_upwards [hf_const.symm, hg_const.symm] with Ï‰ hf hg
      rw [hf, hg]

/-!
## Extension to simple functions and bounded measurables (Â§C2)
-/

/-- **Conditional independence extends to simple functions.**

If Y âŠ¥âŠ¥_W Z for indicators, then the factorization property extends to simple functions
via linearity of conditional expectation.

**Mathematical content:** For simple functions f(Y) and g(Z):
E[f(Y)Â·g(Z)|Ïƒ(W)] = E[f(Y)|Ïƒ(W)]Â·E[g(Z)|Ïƒ(W)]

**Proof strategy:** Express simple functions as linear combinations of indicators,
then use linearity of conditional expectation and the indicator factorization.
-/
lemma condIndep_simpleFunc (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³)
    (h_indep : CondIndep Î¼ Y Z W)
    (f : Î± â†’ â„) (g : Î² â†’ â„)
    -- TODO: Need simple function hypotheses and proper statement
    :
    True := by
  trivial
  /-
  Proof outline:
  1. Express f = Î£áµ¢ aáµ¢ Â· 1_{Aáµ¢} as finite linear combination
  2. Express g = Î£â±¼ bâ±¼ Â· 1_{Bâ±¼} as finite linear combination
  3. Use bilinearity: E[(Î£áµ¢ aáµ¢ 1_{Aáµ¢})Â·(Î£â±¼ bâ±¼ 1_{Bâ±¼})|W]
      = Î£áµ¢â±¼ aáµ¢ bâ±¼ E[1_{Aáµ¢}Â·1_{Bâ±¼}|W]
  4. Apply h_indep to each term: = Î£áµ¢â±¼ aáµ¢ bâ±¼ E[1_{Aáµ¢}|W]Â·E[1_{Bâ±¼}|W]
  5. Factor back: = (Î£áµ¢ aáµ¢ E[1_{Aáµ¢}|W])Â·(Î£â±¼ bâ±¼ E[1_{Bâ±¼}|W])
      = E[f|W]Â·E[g|W]
  -/

/-- **Conditional independence extends to bounded measurable functions (monotone class).**

If Y âŠ¥âŠ¥_W Z for indicators, then by approximation the factorization extends to all
bounded measurable functions.

**Mathematical content:** For bounded measurable f(Y) and g(Z):
E[f(Y)Â·g(Z)|Ïƒ(W)] = E[f(Y)|Ïƒ(W)]Â·E[g(Z)|Ïƒ(W)]

**Proof strategy:** Use monotone class theorem:
1. Simple functions are dense in bounded measurables
2. Conditional expectation is continuous w.r.t. bounded convergence
3. Approximate f, g by simple functions fâ‚™, gâ‚™
4. Pass to limit using dominated convergence

This is the key extension that enables proving measurability properties.
-/
lemma condIndep_boundedMeasurable (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³)
    (h_indep : CondIndep Î¼ Y Z W)
    (f : Î± â†’ â„) (g : Î² â†’ â„)
    (hf_meas : Measurable f) (hg_meas : Measurable g)
    (hf_bdd : âˆƒ C, âˆ€ x, |f x| â‰¤ C) (hg_bdd : âˆƒ C, âˆ€ x, |g x| â‰¤ C) :
    Î¼[ (f âˆ˜ Y) * (g âˆ˜ Z) | MeasurableSpace.comap W inferInstance ] =áµ[Î¼]
    Î¼[ f âˆ˜ Y | MeasurableSpace.comap W inferInstance ] *
    Î¼[ g âˆ˜ Z | MeasurableSpace.comap W inferInstance ] := by
  sorry
  /-
  Proof outline (full monotone class argument):
  1. Define the class H of pairs (f,g) satisfying the factorization
  2. Show H contains all indicator pairs (by h_indep) âœ“
  3. Show H contains all simple function pairs (by linearity)
  4. Show H is closed under bounded monotone limits (by dominated convergence)
  5. By monotone class theorem, H contains all bounded measurables
  6. Therefore the factorization holds for bounded measurable f, g
  -/

/-!
## Extension to product Ïƒ-algebras
-/

/-- **Conditional expectation projection from conditional independence (helper).**

When Y âŠ¥âŠ¥_W Z, conditioning on (Z,W) gives the same result as conditioning on W alone
for indicator functions of Y.

This is a key technical lemma used to prove the main projection theorem.
-/
lemma condExp_project_of_condIndep (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³)
    (hY : Measurable Y) (hZ : Measurable Z) (hW : Measurable W)
    (h_indep : CondIndep Î¼ Y Z W)
    {A : Set Î±} (hA : MeasurableSet A) :
    Î¼[ Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
       | MeasurableSpace.comap (fun Ï‰ => (Z Ï‰, W Ï‰)) inferInstance ]
      =áµ[Î¼]
    Î¼[ Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
       | MeasurableSpace.comap W inferInstance ] := by
  -- Strategy: Use uniqueness characterization of conditional expectation
  -- Show that both CEs have the same integrals on all Ïƒ(W)-measurable sets
  let mW := MeasurableSpace.comap W inferInstance
  let mZW := MeasurableSpace.comap (fun Ï‰ => (Z Ï‰, W Ï‰)) inferInstance
  let f := Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))

  -- Ïƒ-algebra ordering: Ïƒ(W) âŠ† Ïƒ(Z,W)
  have hle : mW â‰¤ mZW := by
    intro s hs
    obtain âŸ¨T, hT_meas, rflâŸ© := hs
    use Set.univ Ã—Ë¢ T
    constructor
    Â· exact MeasurableSet.univ.prod hT_meas
    Â· ext Ï‰; simp [Set.mem_preimage, Set.mem_prod]

  -- Integrability
  have hf_int : Integrable f Î¼ := by
    apply Integrable.indicator
    Â· exact integrable_const (1 : â„)
    Â· exact hY hA

  -- Key insight: Use tower property and apply uniqueness on Ïƒ(Z,W)
  -- We show Î¼[f|mW] has the same set integrals as f on all Ïƒ(Z,W)-sets

  -- Ïƒ-algebra orderings
  have hmZW_le : mZW â‰¤ _ := (hZ.prodMk hW).comap_le  -- Ïƒ(Z,W) â‰¤ ğ“œ(Î©)

  -- Î¼[f|mW] is Ïƒ(W)-measurable, hence also Ïƒ(Z,W)-measurable
  have hgm : AEStronglyMeasurable[mZW] (Î¼[f | mW]) Î¼ := by
    refine AEStronglyMeasurable.mono ?_ hle
    exact stronglyMeasurable_condExp.aestronglyMeasurable

  -- For any S âˆˆ Ïƒ(Z,W): âˆ«_S Î¼[f|mW] = âˆ«_S f
  have hg_eq : âˆ€ s : Set Î©, MeasurableSet[mZW] s â†’ Î¼ s < âˆ â†’
      âˆ« x in s, (Î¼[f | mW]) x âˆ‚Î¼ = âˆ« x in s, f x âˆ‚Î¼ := by
    intro s hs hÎ¼s
    -- Use tower property: Î¼[Î¼[f|mZW]|mW] = Î¼[f|mW]
    have tower : Î¼[Î¼[f | mZW] | mW] =áµ[Î¼] Î¼[f | mW] :=
      condExp_condExp_of_le hle hmZW_le
    -- Therefore âˆ«_S Î¼[f|mW] = âˆ«_S Î¼[Î¼[f|mZW]|mW]
    have eq1 : âˆ« x in s, Î¼[f | mW] x âˆ‚Î¼ = âˆ« x in s, Î¼[Î¼[f | mZW] | mW] x âˆ‚Î¼ :=
      setIntegral_congr_ae (hmZW_le s hs) tower.symm
    -- And âˆ«_S Î¼[Î¼[f|mZW]|mW] = âˆ«_S Î¼[f|mZW] when S âˆˆ Ïƒ(W)...
    -- But S âˆˆ Ïƒ(Z,W), not necessarily Ïƒ(W)!
    -- So we need to use conditional independence here
    sorry

  -- Apply uniqueness: Î¼[f|mW] =áµ Î¼[f|mZW]
  exact (ae_eq_condExp_of_forall_setIntegral_eq hmZW_le hf_int
    (fun _ _ _ => integrable_condExp.integrableOn) hg_eq hgm).symm

/-- **Conditional expectation projection from conditional independence.**

When Y âŠ¥âŠ¥_W Z, conditioning on (Z,W) gives the same result as conditioning on W alone
for functions of Y.

**Key insight:** Conditional independence means that knowing Z provides no additional
information about Y beyond what W already provides. Therefore E[f(Y)|Ïƒ(Z,W)] = E[f(Y)|Ïƒ(W)].

**Proof strategy:**
1. By uniqueness, suffices to show integrals match on Ïƒ(W)-sets
2. For S âˆˆ Ïƒ(W), we have S âˆˆ Ïƒ(Z,W) since Ïƒ(W) â‰¤ Ïƒ(Z,W)
3. So âˆ«_S E[f(Y)|Ïƒ(Z,W)] = âˆ«_S f(Y) by conditional expectation property
4. And âˆ«_S E[f(Y)|Ïƒ(W)] = âˆ«_S f(Y) by conditional expectation property
5. Therefore the integrals match, giving the result

**Alternative via conditional independence definition:**
- Can show E[f(Y)|Ïƒ(Z,W)] is Ïƒ(W)-measurable by using the factorization from CondIndep
- Then apply that conditional expectation of a Ïƒ(W)-measurable function w.r.t. Ïƒ(W) is identity

TODO: Complete this proof using the integral-matching strategy.
-/
theorem condIndep_project (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³)
    (hY : Measurable Y) (hZ : Measurable Z) (hW : Measurable W)
    (h_indep : CondIndep Î¼ Y Z W)
    {A : Set Î±} (hA : MeasurableSet A) :
    Î¼[ Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
       | MeasurableSpace.comap (fun Ï‰ => (Z Ï‰, W Ï‰)) inferInstance ]
      =áµ[Î¼]
    Î¼[ Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
       | MeasurableSpace.comap W inferInstance ] := by
  -- This follows directly from the helper lemma
  exact condExp_project_of_condIndep Î¼ Y Z W hY hZ hW h_indep hA

end  -- noncomputable section
