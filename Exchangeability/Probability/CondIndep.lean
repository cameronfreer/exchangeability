/-
Copyright (c) 2025 Cameron Freer. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: Cameron Freer
-/
import Mathlib.Probability.ConditionalExpectation
import Mathlib.MeasureTheory.Function.ConditionalExpectation.Basic
import Mathlib.MeasureTheory.Measure.Typeclasses.Probability
import Exchangeability.Probability.CondExpHelpers

/-!
# Conditional Independence

This file defines conditional independence for random variables and establishes
basic properties. The definition uses indicator functions on measurable rectangles,
which can then be extended to bounded measurable functions via monotone class arguments.

## Main definitions

* `CondIndep Y Z W Î¼`: Y and Z are conditionally independent given W under measure Î¼,
  denoted Y âŠ¥âŠ¥_W Z, defined via indicator test functions on Borel sets.

## Main results

* `condIndep_symm`: Conditional independence is symmetric (Y âŠ¥âŠ¥_W Z â†” Z âŠ¥âŠ¥_W Y)
* `condIndep_of_indep`: Unconditional independence implies conditional independence

## Implementation notes

We use an indicator-based characterization rather than Ïƒ-algebra formalism to avoid
requiring a full conditional distribution API. The definition states that for all
Borel sets A, B:

  E[1_A(Y) Â· 1_B(Z) | Ïƒ(W)] = E[1_A(Y) | Ïƒ(W)] Â· E[1_B(Z) | Ïƒ(W)]  a.e.

This is equivalent to the standard Ïƒ-algebra definition but more elementary to work with.

## References

* Kallenberg (2005), *Probabilistic Symmetries and Invariance Principles*, Section 6.1
* Kallenberg (2002), *Foundations of Modern Probability*, Chapter 6

## TODO

* Extend from indicators to bounded measurable functions (monotone class argument)
* Prove conditional independence from distributional equality (Kallenberg Lemma 1.3)
* Prove projection property: If Y âŠ¥âŠ¥_W Z, then E[f(Y)|Ïƒ(Z,W)] = E[f(Y)|Ïƒ(W)]

-/

noncomputable section
open scoped MeasureTheory ENNReal
open MeasureTheory ProbabilityTheory Set

variable {Î© Î± Î² Î³ : Type*}
variable [MeasurableSpace Î©] [MeasurableSpace Î±] [MeasurableSpace Î²] [MeasurableSpace Î³]

/-!
## Definition of conditional independence
-/

/-- **Conditional independence via indicator test functions.**

Random variables Y and Z are **conditionally independent given W** under measure Î¼,
denoted Y âŠ¥âŠ¥_W Z, if for all Borel sets A and B:

  E[1_A(Y) Â· 1_B(Z) | Ïƒ(W)] = E[1_A(Y) | Ïƒ(W)] Â· E[1_B(Z) | Ïƒ(W)]  a.e.

**Mathematical content:** This says that knowing W, the events {Y âˆˆ A} and {Z âˆˆ B}
are independent: P(Y âˆˆ A, Z âˆˆ B | W) = P(Y âˆˆ A | W) Â· P(Z âˆˆ B | W).

**Why indicators suffice:** By linearity and approximation, this extends to all bounded
measurable functions. The key is that indicators generate the bounded measurable functions
via monotone class arguments.

**Relation to Ïƒ-algebra definition:** This is equivalent to Ïƒ(Y) âŠ¥âŠ¥_Ïƒ(W) Ïƒ(Z), but
stated more elementarily without requiring full conditional probability machinery.

**Implementation:** We use `Set.indicator` for the characteristic function 1_A.
-/
def CondIndep {Î© Î± Î² Î³ : Type*}
    [MeasurableSpace Î©] [MeasurableSpace Î±] [MeasurableSpace Î²] [MeasurableSpace Î³]
    (Î¼ : Measure Î©) (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³) : Prop :=
  âˆ€ (A : Set Î±) (B : Set Î²), MeasurableSet A â†’ MeasurableSet B â†’
    Î¼[ (Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))) *
       (Set.indicator (Z â»Â¹' B) (fun _ => (1 : â„)))
       | MeasurableSpace.comap W inferInstance ]
      =áµ[Î¼]
    Î¼[ Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
       | MeasurableSpace.comap W inferInstance ]
    *
    Î¼[ Set.indicator (Z â»Â¹' B) (fun _ => (1 : â„))
       | MeasurableSpace.comap W inferInstance ]

/-!
## Basic properties
-/

/-- **Symmetry of conditional independence.**

If Y âŠ¥âŠ¥_W Z, then Z âŠ¥âŠ¥_W Y. This follows immediately from commutativity of multiplication.
-/
theorem condIndep_symm (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³) :
    CondIndep Î¼ Y Z W â†” CondIndep Î¼ Z Y W := by
  constructor <;> intro h A B hA hB
  Â· -- Y âŠ¥âŠ¥_W Z implies Z âŠ¥âŠ¥_W Y
    have := h B A hB hA
    -- Swap multiplication order
    simp only [mul_comm] at this âŠ¢
    exact this
  Â· -- Z âŠ¥âŠ¥_W Y implies Y âŠ¥âŠ¥_W Z (same proof by symmetry)
    have := h B A hB hA
    simp only [mul_comm] at this âŠ¢
    exact this

/-!
## Helper lemmas for independence and conditional expectation
-/

/-- **Conditional expectation against an independent Ïƒ-algebra is constant.**

If X is integrable and measurable with respect to a Ïƒ-algebra independent of Ïƒ(W),
then E[X | Ïƒ(W)] = E[X] almost everywhere.

This is the key property that makes independence "pass through" conditioning:
knowing W provides no information about X when X âŠ¥ W.
-/
lemma condExp_const_of_indepFun (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    {X : Î© â†’ â„} {W : Î© â†’ Î³}
    (hX : Measurable X) (hW : Measurable W)
    (h_indep : IndepFun X W Î¼)
    (hX_int : Integrable X Î¼) :
    Î¼[X | MeasurableSpace.comap W inferInstance] =áµ[Î¼] (fun _ => Î¼[X]) := by
  -- Convert IndepFun to Indep of Ïƒ-algebras
  rw [IndepFun_iff_Indep] at h_indep
  -- Apply condExp_indep_eq: E[X|Ïƒ(W)] = E[X] when Ïƒ(X) âŠ¥ Ïƒ(W)
  refine condExp_indep_eq hX.comap_le hW.comap_le ?_ h_indep
  -- X is Ïƒ(X)-strongly measurable (X is measurable from (Î©, Ïƒ(X)) to â„ by definition of comap)
  have : @Measurable Î© â„ (MeasurableSpace.comap X inferInstance) inferInstance X :=
    Measurable.of_comap_le le_rfl
  exact this.stronglyMeasurable

/-- Extract independence of first component from pair independence. -/
lemma IndepFun.of_comp_left_fst {Y : Î© â†’ Î±} {Z : Î© â†’ Î²} {W : Î© â†’ Î³}
    (h : IndepFun (fun Ï‰ => (Y Ï‰, Z Ï‰)) W Î¼) :
    IndepFun Y W Î¼ := by
  -- Y = Prod.fst âˆ˜ (fun Ï‰ => (Y Ï‰, Z Ï‰))
  -- So Y âŠ¥ W follows from (Y,Z) âŠ¥ W by composition
  have : Y = Prod.fst âˆ˜ (fun Ï‰ => (Y Ï‰, Z Ï‰)) := by rfl
  rw [this]
  exact h.comp measurable_fst measurable_id

/-- Extract independence of second component from pair independence. -/
lemma IndepFun.of_comp_left_snd {Y : Î© â†’ Î±} {Z : Î© â†’ Î²} {W : Î© â†’ Î³}
    (h : IndepFun (fun Ï‰ => (Y Ï‰, Z Ï‰)) W Î¼) :
    IndepFun Z W Î¼ := by
  -- Z = Prod.snd âˆ˜ (fun Ï‰ => (Y Ï‰, Z Ï‰))
  -- So Z âŠ¥ W follows from (Y,Z) âŠ¥ W by composition
  have : Z = Prod.snd âˆ˜ (fun Ï‰ => (Y Ï‰, Z Ï‰)) := by rfl
  rw [this]
  exact h.comp measurable_snd measurable_id

/-!
## Conditional independence from unconditional independence
-/

/-- **Independence plus independence of pair from W implies conditional independence.**

If Y and Z are (unconditionally) independent, and the pair (Y,Z) is independent of W,
then Y âŠ¥âŠ¥_W Z.

**Key insight:** Independence of (Y,Z) from W means the conditional law of (Y,Z) given W
equals the unconditional law, so the factorization E[1_A(Y)Â·1_B(Z)] = E[1_A(Y)]Â·E[1_B(Z)]
survives conditioning on W.

**Counterexample showing Y âŠ¥ Z alone is NOT enough:**
- Y, Z: independent fair coin flips
- W := Y + Z
- Then Y âŠ¥ Z unconditionally, but P(Y=1|Z=1,W=1) = 1 â‰  1/2 = P(Y=1|W=1),
  so Y and Z are NOT conditionally independent given W.

**Proof strategy:**
1. Since (Y,Z) âŠ¥ W, conditional expectation of any function of (Y,Z) given Ïƒ(W)
   is the constant E[that function].
2. Apply to 1_A(Y), 1_B(Z), and their product.
3. The unconditional factorization E[1_A(Y)Â·1_B(Z)] = E[1_A(Y)]Â·E[1_B(Z)] (from Y âŠ¥ Z)
   transfers to the conditional expectations.
-/
theorem condIndep_of_indep_pair (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³)
    (hY : Measurable Y) (hZ : Measurable Z) (hW : Measurable W)
    (hYZ_indep : IndepFun Y Z Î¼)
    (hPairW_indep : IndepFun (fun Ï‰ => (Y Ï‰, Z Ï‰)) W Î¼) :
    CondIndep Î¼ Y Z W := by
  intro A B hA hB
  -- Define the indicator functions
  let f := Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
  let g := Set.indicator (Z â»Â¹' B) (fun _ => (1 : â„))

  -- f and g are measurable and integrable
  have hf_meas : Measurable f := measurable_const.indicator (hY hA)
  have hg_meas : Measurable g := measurable_const.indicator (hZ hB)
  have hf_int : Integrable f Î¼ := (integrable_const (1 : â„)).indicator (hY hA)
  have hg_int : Integrable g Î¼ := (integrable_const (1 : â„)).indicator (hZ hB)

  -- Extract Y âŠ¥ W and Z âŠ¥ W from pair independence
  have hY_W_indep : IndepFun Y W Î¼ := IndepFun.of_comp_left_fst hPairW_indep
  have hZ_W_indep : IndepFun Z W Î¼ := IndepFun.of_comp_left_snd hPairW_indep

  -- Key insight: f, g, and f*g are all independent of W
  -- Therefore their conditional expectations given Ïƒ(W) are constants

  -- Step 1: f is a function of Y, so f âŠ¥ W
  -- f = (Set.indicator A (fun _ => 1)) âˆ˜ Y
  have hf_indep : IndepFun f W Î¼ := by
    have : f = (Set.indicator A (fun _ => (1 : â„))) âˆ˜ Y := by
      ext Ï‰
      simp only [Function.comp_apply, Set.indicator_apply]
      rfl
    rw [this]
    exact hY_W_indep.comp (measurable_const.indicator hA) measurable_id

  -- Step 2: g is a function of Z, so g âŠ¥ W
  have hg_indep : IndepFun g W Î¼ := by
    have : g = (Set.indicator B (fun _ => (1 : â„))) âˆ˜ Z := by
      ext Ï‰
      simp only [Function.comp_apply, Set.indicator_apply]
      rfl
    rw [this]
    exact hZ_W_indep.comp (measurable_const.indicator hB) measurable_id

  -- Step 3: f * g is a function of (Y,Z), so f * g âŠ¥ W
  have hfg_indep : IndepFun (f * g) W Î¼ := by
    classical
    have : f * g = (fun p => Set.indicator (A Ã—Ë¢ B) (fun _ => (1 : â„)) p) âˆ˜ (fun Ï‰ => (Y Ï‰, Z Ï‰)) := by
      ext Ï‰
      show f Ï‰ * g Ï‰ = Set.indicator (A Ã—Ë¢ B) (fun _ => (1 : â„)) (Y Ï‰, Z Ï‰)
      rw [Set.indicator_apply (A Ã—Ë¢ B), Set.indicator_apply (Y â»Â¹' A), Set.indicator_apply (Z â»Â¹' B)]
      simp only [Pi.mul_apply, Set.mem_prod, Set.mem_preimage]
      split_ifs <;> norm_num
    rw [this]
    exact hPairW_indep.comp (measurable_const.indicator (hA.prod hB)) measurable_id

  -- Step 4: Apply condExp_const_of_indepFun to get conditional expectations are constants
  have hf_ce : Î¼[f | MeasurableSpace.comap W inferInstance] =áµ[Î¼] (fun _ => Î¼[f]) :=
    condExp_const_of_indepFun Î¼ hf_meas hW hf_indep hf_int

  have hg_ce : Î¼[g | MeasurableSpace.comap W inferInstance] =áµ[Î¼] (fun _ => Î¼[g]) :=
    condExp_const_of_indepFun Î¼ hg_meas hW hg_indep hg_int

  have hfg_meas : Measurable (f * g) := hf_meas.mul hg_meas
  have hfg_int : Integrable (f * g) Î¼ := by
    -- f * g = 1_{Yâ»Â¹A âˆ© Zâ»Â¹B}
    have : f * g = Set.indicator (Y â»Â¹' A âˆ© Z â»Â¹' B) (fun _ => (1 : â„)) := by
      classical
      ext Ï‰
      rw [Set.indicator_apply (Y â»Â¹' A), Set.indicator_apply (Z â»Â¹' B), Set.indicator_apply]
      simp only [Pi.mul_apply, Set.mem_inter_iff, Set.mem_preimage]
      split_ifs <;> norm_num
    rw [this]
    exact (integrable_const (1 : â„)).indicator ((hY hA).inter (hZ hB))
  have hfg_ce : Î¼[f * g | MeasurableSpace.comap W inferInstance] =áµ[Î¼] (fun _ => Î¼[f * g]) :=
    condExp_const_of_indepFun Î¼ hfg_meas hW hfg_indep hfg_int

  -- Step 5: Use Y âŠ¥ Z to get unconditional factorization E[f*g] = E[f] * E[g]
  -- Since f is a function of Y and g is a function of Z, f âŠ¥ g follows from Y âŠ¥ Z
  have hfg_indep' : IndepFun f g Î¼ := by
    have hf_comp : f = (Set.indicator A (fun _ => (1 : â„))) âˆ˜ Y := by
      ext Ï‰
      show f Ï‰ = Set.indicator A (fun _ => 1) (Y Ï‰)
      rfl
    have hg_comp : g = (Set.indicator B (fun _ => (1 : â„))) âˆ˜ Z := by
      ext Ï‰
      show g Ï‰ = Set.indicator B (fun _ => 1) (Z Ï‰)
      rfl
    rw [hf_comp, hg_comp]
    exact hYZ_indep.comp (measurable_const.indicator hA) (measurable_const.indicator hB)

  have h_factor : Î¼[f * g] = Î¼[f] * Î¼[g] := by
    sorry  -- Need to find correct integral lemma

  -- Step 6: Combine everything
  calc Î¼[f * g | MeasurableSpace.comap W inferInstance]
      =áµ[Î¼] (fun _ => Î¼[f * g]) := hfg_ce
    _ = (fun _ => Î¼[f] * Î¼[g]) := by rw [h_factor]
    _ =áµ[Î¼] (fun _ => Î¼[f]) * (fun _ => Î¼[g]) := by rfl
    _ =áµ[Î¼] Î¼[f | MeasurableSpace.comap W inferInstance] * Î¼[g | MeasurableSpace.comap W inferInstance] :=
        Filter.EventuallyEq.mul hf_ce.symm hg_ce.symm

/-!
## Extension to simple functions and bounded measurables (Â§C2)
-/

/-- **Conditional independence extends to simple functions.**

If Y âŠ¥âŠ¥_W Z for indicators, then the factorization property extends to simple functions
via linearity of conditional expectation.

**Mathematical content:** For simple functions f(Y) and g(Z):
E[f(Y)Â·g(Z)|Ïƒ(W)] = E[f(Y)|Ïƒ(W)]Â·E[g(Z)|Ïƒ(W)]

**Proof strategy:** Express simple functions as linear combinations of indicators,
then use linearity of conditional expectation and the indicator factorization.
-/
lemma condIndep_simpleFunc (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³)
    (h_indep : CondIndep Î¼ Y Z W)
    (f : Î± â†’ â„) (g : Î² â†’ â„)
    -- TODO: Need simple function hypotheses and proper statement
    :
    True := by
  trivial
  /-
  Proof outline:
  1. Express f = Î£áµ¢ aáµ¢ Â· 1_{Aáµ¢} as finite linear combination
  2. Express g = Î£â±¼ bâ±¼ Â· 1_{Bâ±¼} as finite linear combination
  3. Use bilinearity: E[(Î£áµ¢ aáµ¢ 1_{Aáµ¢})Â·(Î£â±¼ bâ±¼ 1_{Bâ±¼})|W]
      = Î£áµ¢â±¼ aáµ¢ bâ±¼ E[1_{Aáµ¢}Â·1_{Bâ±¼}|W]
  4. Apply h_indep to each term: = Î£áµ¢â±¼ aáµ¢ bâ±¼ E[1_{Aáµ¢}|W]Â·E[1_{Bâ±¼}|W]
  5. Factor back: = (Î£áµ¢ aáµ¢ E[1_{Aáµ¢}|W])Â·(Î£â±¼ bâ±¼ E[1_{Bâ±¼}|W])
      = E[f|W]Â·E[g|W]
  -/

/-- **Conditional independence extends to bounded measurable functions (monotone class).**

If Y âŠ¥âŠ¥_W Z for indicators, then by approximation the factorization extends to all
bounded measurable functions.

**Mathematical content:** For bounded measurable f(Y) and g(Z):
E[f(Y)Â·g(Z)|Ïƒ(W)] = E[f(Y)|Ïƒ(W)]Â·E[g(Z)|Ïƒ(W)]

**Proof strategy:** Use monotone class theorem:
1. Simple functions are dense in bounded measurables
2. Conditional expectation is continuous w.r.t. bounded convergence
3. Approximate f, g by simple functions fâ‚™, gâ‚™
4. Pass to limit using dominated convergence

This is the key extension that enables proving measurability properties.
-/
lemma condIndep_boundedMeasurable (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³)
    (h_indep : CondIndep Î¼ Y Z W)
    (f : Î± â†’ â„) (g : Î² â†’ â„)
    (hf_meas : Measurable f) (hg_meas : Measurable g)
    (hf_bdd : âˆƒ C, âˆ€ x, |f x| â‰¤ C) (hg_bdd : âˆƒ C, âˆ€ x, |g x| â‰¤ C) :
    Î¼[ (f âˆ˜ Y) * (g âˆ˜ Z) | MeasurableSpace.comap W inferInstance ] =áµ[Î¼]
    Î¼[ f âˆ˜ Y | MeasurableSpace.comap W inferInstance ] *
    Î¼[ g âˆ˜ Z | MeasurableSpace.comap W inferInstance ] := by
  sorry
  /-
  Proof outline (full monotone class argument):
  1. Define the class H of pairs (f,g) satisfying the factorization
  2. Show H contains all indicator pairs (by h_indep) âœ“
  3. Show H contains all simple function pairs (by linearity)
  4. Show H is closed under bounded monotone limits (by dominated convergence)
  5. By monotone class theorem, H contains all bounded measurables
  6. Therefore the factorization holds for bounded measurable f, g
  -/

/-!
## Extension to product Ïƒ-algebras
-/

/-- **Conditional expectation projection from conditional independence (helper).**

When Y âŠ¥âŠ¥_W Z, conditioning on (Z,W) gives the same result as conditioning on W alone
for indicator functions of Y.

This is a key technical lemma used to prove the main projection theorem.
-/
lemma condExp_project_of_condIndep (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³)
    (hY : Measurable Y) (hZ : Measurable Z) (hW : Measurable W)
    (h_indep : CondIndep Î¼ Y Z W)
    {A : Set Î±} (hA : MeasurableSet A) :
    Î¼[ Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
       | MeasurableSpace.comap (fun Ï‰ => (Z Ï‰, W Ï‰)) inferInstance ]
      =áµ[Î¼]
    Î¼[ Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
       | MeasurableSpace.comap W inferInstance ] := by
  -- Strategy: Use uniqueness characterization of conditional expectation
  -- Show that both CEs have the same integrals on all Ïƒ(W)-measurable sets
  let mW := MeasurableSpace.comap W inferInstance
  let mZW := MeasurableSpace.comap (fun Ï‰ => (Z Ï‰, W Ï‰)) inferInstance
  let f := Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))

  -- Ïƒ-algebra ordering: Ïƒ(W) âŠ† Ïƒ(Z,W)
  have hle : mW â‰¤ mZW := by
    intro s hs
    obtain âŸ¨T, hT_meas, rflâŸ© := hs
    use Set.univ Ã—Ë¢ T
    constructor
    Â· exact MeasurableSet.univ.prod hT_meas
    Â· ext Ï‰; simp [Set.mem_preimage, Set.mem_prod]

  -- Integrability
  have hf_int : Integrable f Î¼ := by
    apply Integrable.indicator
    Â· exact integrable_const (1 : â„)
    Â· exact hY hA

  -- Key insight: Use tower property and apply uniqueness on Ïƒ(Z,W)
  -- We show Î¼[f|mW] has the same set integrals as f on all Ïƒ(Z,W)-sets

  -- Ïƒ-algebra orderings
  have hmZW_le : mZW â‰¤ _ := (hZ.prodMk hW).comap_le  -- Ïƒ(Z,W) â‰¤ ğ“œ(Î©)

  -- Î¼[f|mW] is Ïƒ(W)-measurable, hence also Ïƒ(Z,W)-measurable
  have hgm : AEStronglyMeasurable[mZW] (Î¼[f | mW]) Î¼ := by
    refine AEStronglyMeasurable.mono ?_ hle
    exact stronglyMeasurable_condExp.aestronglyMeasurable

  -- For any S âˆˆ Ïƒ(Z,W): âˆ«_S Î¼[f|mW] = âˆ«_S f
  -- Use Dynkin Ï€-Î» theorem: define C(s) := "integrals match on s"
  have hg_eq : âˆ€ s : Set Î©, MeasurableSet[mZW] s â†’ Î¼ s < âˆ â†’
      âˆ« x in s, (Î¼[f | mW]) x âˆ‚Î¼ = âˆ« x in s, f x âˆ‚Î¼ := by
    -- First show: Ïƒ(Z,W) is generated by rectangles Zâ»Â¹(B) âˆ© Wâ»Â¹(C)
    have mZW_gen : mZW = MeasurableSpace.generateFrom
        {s | âˆƒ (B : Set Î²) (C : Set Î³), MeasurableSet B âˆ§ MeasurableSet C âˆ§
             s = Z â»Â¹' B âˆ© W â»Â¹' C} := by
      -- Ïƒ(Z,W) = comap (Z,W) (Ïƒ(Î²Ã—Î³))
      -- Ïƒ(Î²Ã—Î³) = generateFrom {B Ã—Ë¢ C | ...} by generateFrom_prod
      -- comap commutes with generateFrom
      unfold mZW
      conv_lhs => arg 2; rw [â† generateFrom_prod (Î± := Î²) (Î² := Î³)]
      rw [MeasurableSpace.comap_generateFrom]
      congr 1
      ext s
      constructor
      Â· intro âŸ¨t, ht_mem, ht_eqâŸ©
        -- t âˆˆ image2 (Â· Ã—Ë¢ Â·) ... means âˆƒ B C, t = B Ã—Ë¢ C
        -- ht_mem : t âˆˆ image2 (Â·Ã—Ë¢Â·) {B | MeasurableSet B} {C | MeasurableSet C}
        simp only [Set.mem_image2, Set.mem_setOf_eq] at ht_mem
        obtain âŸ¨B, hB, C, hC, rflâŸ© := ht_mem
        use B, C, hB, hC
        -- Need: (Z,W)â»Â¹(B Ã—Ë¢ C) = Zâ»Â¹B âˆ© Wâ»Â¹C
        rw [â† ht_eq]
        ext Ï‰
        simp only [Set.mem_inter_iff, Set.mem_preimage, Set.mem_prod]
      Â· intro âŸ¨B, C, hB, hC, hs_eqâŸ©
        -- s = Zâ»Â¹B âˆ© Wâ»Â¹C, need to show it's in the preimage image
        simp only [Set.mem_image, Set.mem_image2, Set.mem_setOf_eq]
        use B Ã—Ë¢ C
        refine âŸ¨âŸ¨B, hB, C, hC, rflâŸ©, ?_âŸ©
        rw [hs_eq]
        ext Ï‰
        simp only [Set.mem_inter_iff, Set.mem_preimage, Set.mem_prod]

    -- Rectangles form a Ï€-system
    have h_pi : IsPiSystem {s | âˆƒ (B : Set Î²) (C : Set Î³), MeasurableSet B âˆ§ MeasurableSet C âˆ§
                                   s = Z â»Â¹' B âˆ© W â»Â¹' C} := by
      -- Need to show: intersection of two rectangles is a rectangle
      intro sâ‚ hsâ‚ sâ‚‚ hsâ‚‚ _
      obtain âŸ¨Bâ‚, Câ‚, hBâ‚, hCâ‚, rflâŸ© := hsâ‚
      obtain âŸ¨Bâ‚‚, Câ‚‚, hBâ‚‚, hCâ‚‚, rflâŸ© := hsâ‚‚
      -- (Zâ»Â¹Bâ‚ âˆ© Wâ»Â¹Câ‚) âˆ© (Zâ»Â¹Bâ‚‚ âˆ© Wâ»Â¹Câ‚‚) = Zâ»Â¹(Bâ‚ âˆ© Bâ‚‚) âˆ© Wâ»Â¹(Câ‚ âˆ© Câ‚‚)
      use Bâ‚ âˆ© Bâ‚‚, Câ‚ âˆ© Câ‚‚
      refine âŸ¨hBâ‚.inter hBâ‚‚, hCâ‚.inter hCâ‚‚, ?_âŸ©
      ext Ï‰
      simp only [Set.mem_inter_iff, Set.mem_preimage]
      tauto

    -- Apply Ï€-Î» induction
    intro s hs hÎ¼s
    apply MeasurableSpace.induction_on_inter (C := fun s _ => âˆ« x in s, (Î¼[f | mW]) x âˆ‚Î¼ = âˆ« x in s, f x âˆ‚Î¼)
      mZW_gen h_pi

    Â· -- Empty set
      simp

    Â· -- Basic case: rectangles Zâ»Â¹(B) âˆ© Wâ»Â¹(C)
      intro t ht
      obtain âŸ¨B, C, hB, hC, rflâŸ© := ht
      -- Strategy: Use that Zâ»Â¹B âˆ© Wâ»Â¹C is in mZW, so by tower property and setIntegral_condExp
      -- Key: Zâ»Â¹B âˆ© Wâ»Â¹C âˆˆ Ïƒ(Z,W), so âˆ«_{Zâ»Â¹B âˆ© Wâ»Â¹C} Î¼[f|mZW] = âˆ«_{Zâ»Â¹B âˆ© Wâ»Â¹C} f
      -- And we'll show âˆ«_{Zâ»Â¹B âˆ© Wâ»Â¹C} Î¼[f|mW] = âˆ«_{Zâ»Â¹B âˆ© Wâ»Â¹C} Î¼[f|mZW]

      -- Rectangle is in mZW
      have hrect : MeasurableSet[mZW] (Z â»Â¹' B âˆ© W â»Â¹' C) := by
        -- Zâ»Â¹B âˆ© Wâ»Â¹C = (Z,W)â»Â¹(B Ã—Ë¢ C)
        have : Z â»Â¹' B âˆ© W â»Â¹' C = (fun Ï‰ => (Z Ï‰, W Ï‰)) â»Â¹' (B Ã—Ë¢ C) := by
          ext Ï‰
          simp only [Set.mem_inter_iff, Set.mem_preimage, Set.mem_prod]
        rw [this]
        exact measurableSet_preimage (Measurable.of_comap_le le_rfl) (hB.prod hC)

      -- By setIntegral_condExp on mZW
      have h1 : âˆ« x in Z â»Â¹' B âˆ© W â»Â¹' C, (Î¼[f | mZW]) x âˆ‚Î¼ = âˆ« x in Z â»Â¹' B âˆ© W â»Â¹' C, f x âˆ‚Î¼ := by
        exact setIntegral_condExp hmZW_le hf_int hrect

      -- By tower property: E[E[f|mZW]|mW] = E[f|mW]
      have h2 : Î¼[Î¼[f | mZW] | mW] =áµ[Î¼] Î¼[f | mW] := by
        exact (condExp_condExp_of_le hle hmZW_le).symm

      -- So âˆ«_{rectangle} E[f|mW] = âˆ«_{rectangle} E[E[f|mZW]|mW]
      have h3 : âˆ« x in Z â»Â¹' B âˆ© W â»Â¹' C, (Î¼[f | mW]) x âˆ‚Î¼ =
                âˆ« x in Z â»Â¹' B âˆ© W â»Â¹' C, (Î¼[Î¼[f | mZW] | mW]) x âˆ‚Î¼ := by
        apply setIntegral_congr_ae (hmZW_le _ hrect)
        filter_upwards [h2] with x hx _
        exact hx.symm

      rw [h3, h1]

      -- Key step: Show âˆ«_{rect} E[E[f|mZW]|mW] = âˆ«_{rect} E[f|mZW]
      -- Strategy: Use conditional independence via h_indep
      -- For f = 1_A(Y), and rectangle Zâ»Â¹B âˆ© Wâ»Â¹C:
      --   âˆ«_{Wâ»Â¹C} E[1_A(Y) Â· 1_B(Z)|mW] = âˆ«_{Wâ»Â¹C} 1_A(Y) Â· 1_B(Z)  (by setIntegral_condExp)
      --   âˆ«_{Wâ»Â¹C} E[1_A(Y)|mW] Â· E[1_B(Z)|mW] = âˆ«_{Zâ»Â¹B âˆ© Wâ»Â¹C} 1_A(Y)  (by CondIndep)
      --
      -- This step requires showing that integrating E[1_A(Y)|mW] Â· E[1_B(Z)|mW] over Wâ»Â¹C
      -- gives the same as integrating E[1_A(Y)|mW] over Zâ»Â¹B âˆ© Wâ»Â¹C
      --
      -- This is the heart of the conditional independence property and requires
      -- a more detailed argument about how conditional expectations interact
      -- with product structures. For now, leaving as sorry to complete the framework.
      sorry

    Â· -- Complement
      intro t htm ht_ind
      -- For complement: âˆ«_{t} g + âˆ«_{tá¶œ} g = âˆ«_Î© g, so âˆ«_{tá¶œ} g = âˆ«_Î© g - âˆ«_t g
      have h_add : âˆ« x in t, (Î¼[f | mW]) x âˆ‚Î¼ + âˆ« x in tá¶œ, (Î¼[f | mW]) x âˆ‚Î¼ = âˆ« x, (Î¼[f | mW]) x âˆ‚Î¼ := by
        exact integral_add_complâ‚€ (hmZW_le _ htm).nullMeasurableSet integrable_condExp
      have h_add' : âˆ« x in t, f x âˆ‚Î¼ + âˆ« x in tá¶œ, f x âˆ‚Î¼ = âˆ« x, f x âˆ‚Î¼ := by
        exact integral_add_complâ‚€ (hmZW_le _ htm).nullMeasurableSet hf_int
      rw [ht_ind (measure_lt_top Î¼ t)] at h_add
      linarith [integral_condExp hle, integral_condExp hle]

    Â· -- Countable disjoint union
      intro t_seq hdisjoint htm_seq ht_ind_seq
      -- For disjoint union: âˆ«_{â‹ƒáµ¢ táµ¢} g = Î£áµ¢ âˆ«_{táµ¢} g
      have h_union : HasSum (fun n => âˆ« x in t_seq n, (Î¼[f | mW]) x âˆ‚Î¼) (âˆ« x in â‹ƒ n, t_seq n, (Î¼[f | mW]) x âˆ‚Î¼) := by
        apply hasSum_integral_iUnion (fun i => (hmZW_le _ (htm_seq i)).nullMeasurableSet)
        Â· exact fun i j hij => (hdisjoint hij).aedisjoint
        Â· exact integrable_condExp.integrableOn
      have h_union' : HasSum (fun n => âˆ« x in t_seq n, f x âˆ‚Î¼) (âˆ« x in â‹ƒ n, t_seq n, f x âˆ‚Î¼) := by
        apply hasSum_integral_iUnion (fun i => (hmZW_le _ (htm_seq i)).nullMeasurableSet)
        Â· exact fun i j hij => (hdisjoint hij).aedisjoint
        Â· exact hf_int.integrableOn
      apply h_union.unique
      rw [â† h_union'.tsum_eq]
      congr 1
      ext i
      exact ht_ind_seq i (measure_lt_top Î¼ (t_seq i))

    Â· exact hs

  -- Apply uniqueness: Î¼[f|mW] =áµ Î¼[f|mZW]
  exact (ae_eq_condExp_of_forall_setIntegral_eq hmZW_le hf_int
    (fun _ _ _ => integrable_condExp.integrableOn) hg_eq hgm).symm

/-- **Conditional expectation projection from conditional independence.**

When Y âŠ¥âŠ¥_W Z, conditioning on (Z,W) gives the same result as conditioning on W alone
for functions of Y.

**Key insight:** Conditional independence means that knowing Z provides no additional
information about Y beyond what W already provides. Therefore E[f(Y)|Ïƒ(Z,W)] = E[f(Y)|Ïƒ(W)].

**Proof strategy:**
1. By uniqueness, suffices to show integrals match on Ïƒ(W)-sets
2. For S âˆˆ Ïƒ(W), we have S âˆˆ Ïƒ(Z,W) since Ïƒ(W) â‰¤ Ïƒ(Z,W)
3. So âˆ«_S E[f(Y)|Ïƒ(Z,W)] = âˆ«_S f(Y) by conditional expectation property
4. And âˆ«_S E[f(Y)|Ïƒ(W)] = âˆ«_S f(Y) by conditional expectation property
5. Therefore the integrals match, giving the result

**Alternative via conditional independence definition:**
- Can show E[f(Y)|Ïƒ(Z,W)] is Ïƒ(W)-measurable by using the factorization from CondIndep
- Then apply that conditional expectation of a Ïƒ(W)-measurable function w.r.t. Ïƒ(W) is identity

TODO: Complete this proof using the integral-matching strategy.
-/
theorem condIndep_project (Î¼ : Measure Î©) [IsProbabilityMeasure Î¼]
    (Y : Î© â†’ Î±) (Z : Î© â†’ Î²) (W : Î© â†’ Î³)
    (hY : Measurable Y) (hZ : Measurable Z) (hW : Measurable W)
    (h_indep : CondIndep Î¼ Y Z W)
    {A : Set Î±} (hA : MeasurableSet A) :
    Î¼[ Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
       | MeasurableSpace.comap (fun Ï‰ => (Z Ï‰, W Ï‰)) inferInstance ]
      =áµ[Î¼]
    Î¼[ Set.indicator (Y â»Â¹' A) (fun _ => (1 : â„))
       | MeasurableSpace.comap W inferInstance ] := by
  -- This follows directly from the helper lemma
  exact condExp_project_of_condIndep Î¼ Y Z W hY hZ hW h_indep hA

end  -- noncomputable section
